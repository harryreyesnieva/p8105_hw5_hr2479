---
title: "p8105_hw5_hr2479"
author: "Harry Reyes"
date: "11/16/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 1

The Washington Post made data on homicides in 50 U.S. cities publicly available via a [Github repository](https://github.com/washingtonpost/data-homicides). After downloading the data, here we import and review the dataset.

```{r}
homicide_df = 
  read_csv("./data/homicide-data.csv", na = c("", "Unknown"), show_col_types = FALSE) %>%
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    )) %>%
  relocate(city_state) %>%
  filter(city_state != "Tulsa, AL") 

head(homicide_df)%>%
  knitr::kable()

```

The homicide dataset contains `r nrow(homicide_df)` observations and `r ncol(homicide_df)` variables, including the victim's name, age, race (i.e., `r levels(factor(pull(homicide_df, victim_race)))`), and sex (i.e., `r levels(factor(pull(homicide_df, victim_sex)))`). There is also information on the date the homicide was reported, its disposition (i.e., `r levels(factor(pull(homicide_df, disposition)))`), the city and state of the homicide, and its latitude and longitude. Homicide victims in this dataset had a mean age of `r round(mean(pull(homicide_df, victim_age), na.rm = TRUE))` years. As part of tidying this dataset, I created a city_state variable that combines city and state, and a resolution variable based on the disposition of the case. I also dropped an observation attributed to Tulsa, AL that appears to be an error.

Here I computed the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”) at the city level.

```{r}
citystate_homicide_df = 
  homicide_df %>% 
  select(city_state, disposition, resolution) %>% 
  group_by(city_state) %>% 
  summarize(homicides_total = n(),
            homicides_unsolved = sum(resolution == "unsolved"))

citystate_homicide_df%>%
  knitr::kable()
```

Here, for the city of Baltimore, MD, I estimated the proportion (and confidence intervals) of homicides that are unsolved. It appears to be approximately 65% (95% CI: 63%-66%).

```{r}
baltimore_df = 
  homicide_df %>% 
  filter(city_state == "Baltimore, MD") 

baltimore_summary =
  baltimore_df %>%
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n=n()
  )

baltimore_test = 
  prop.test(
    x = baltimore_summary %>%  pull(unsolved), 
    n = baltimore_summary %>%  pull(n))

baltimore_test %>% 
  broom::tidy()%>%
  select(estimate, starts_with("conf"))%>%
  knitr::kable()
```

After developing my approach for a single city, I then created a function that would similarly estimate the proportion (and confidence intervals) of homicides that are unsolved for each city in the dataset.

```{r}
prop_test_function = function(city_df){
  
  city_summary = 
    city_df %>% 
    summarize(
      unsolved = sum(resolution == "unsolved"),
      n = n()
      )
  
  city_test =
    prop.test(
      x = city_summary %>% pull(unsolved),
      n = city_summary %>% pull(n))
  
  return(city_test)
}
 
result_df = 
  homicide_df %>%
  nest(data = uid:resolution) %>%
  mutate(
    test_results = map(data, prop_test_function),
    tidy_results = map(test_results, broom::tidy)
  ) %>%
  select(city_state, tidy_results) %>%
  unnest(tidy_results) %>%
  select(city_state, estimate, starts_with("conf"))

result_df%>%
  knitr::kable()
```

I also created a plot that shows the estimates and CIs for each city, organizing cities according to the proportion of unsolved homicides.

```{r}
result_df %>%
  mutate(
    city_state = fct_reorder(city_state, estimate)
    ) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


## Problem 2

Based on a [zip file](https://www.p8105.com/data/hw5_data.zip) for a longitudinal study, I created a tidy dataframe containing data from all participants, including the subject ID, arm, and observations over time. I started with a dataframe containing all file names, then iterated over file names and read in data for each subject, saving the result as a new variable in the dataframe. I then tidied the result by pivoting to a longer format.

```{r}
longitudinal_df =
  tibble(
    files = list.files("./data/zip_data/"),
    path = str_c("data/zip_data/", files)
    ) %>% 
  mutate(data = purrr::map(path, read_csv, show_col_types = FALSE)) %>% 
  unnest(data) %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    arm = str_sub(files, 1, 3)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "observation",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week),
         subject_id = files
         ) %>% 
  select(arm, subject_id, week, observation)
```

I also made a spaghetti plot showing observations on each subject over time. Data in the control arm appears relatively stable over time while observations in the experimental appear to increase over time linearly.

```{r}
arm.labs <- c("Control Arm", "Experimental Arm")
names(arm.labs) <- c("con", "exp")

spaghetti_plot = 
  longitudinal_df %>% 
  ggplot(aes(x = week, y = observation, group = subject_id, color = arm)) + 
  geom_line() + 
  geom_point() + 
  facet_grid(~arm,  labeller = labeller(arm = arm.labs)) +
  labs(
      x = "Week", 
      y = "Observations",
      title = "Observations on each subject over time by study arm") +
  theme(plot.title = element_text(hjust = 0.5))

spaghetti_plot
```

## Problem 3

The code chunk below loads the `iris` dataset from the `tidyverse` package and introduces some missing values in each column. The purpose of this problem is to fill in those missing values.

There are two cases to address:

* For numeric variables, you should fill in missing values with the mean of non-missing values
* For character variables, you should fill in missing values with `"virginica"`

Write a function that takes a vector as an argument; replaces missing values using the rules defined above; and returns the resulting vector. Apply this function to the columns of `iris_with_missing` using a `map` statement.

```{r}
set.seed(10)
iris_with_missing = 
  iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))

iris_with_missing

replace_missing = function(x) {
  
  if (is_numeric(x)) {
    mean_nonmissing = round(mean(x, na.rm = TRUE, 1))
    x = replace_na(x, mean_nonmissing)}
  
  else if (is.character(x)) {
    x = replace_na(x, "virginica")}

  return(x)
}

iris_fill =  map_df(iris_with_missing, replace_missing)

iris_fill
```

